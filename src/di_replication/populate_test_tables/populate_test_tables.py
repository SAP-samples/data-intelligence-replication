# First 3 lines generated by di-pyoperator - DO NOT CHANGE (Deleted again when uploaded.)
from utils.mock_di_api import mock_api
api = mock_api(__file__)

import logging
import io
import copy

from datetime import datetime, timezone, timedelta
import pandas as pd
import numpy as np

pd.set_option('mode.chained_assignment',None)

# catching logger messages for separate output
log_stream = io.StringIO()
sh = logging.StreamHandler(stream=log_stream)
sh.setFormatter(logging.Formatter('%(asctime)s ;  %(levelname)s ; %(name)s ; %(message)s', datefmt='%H:%M:%S'))
api.logger.addHandler(sh)

def on_data(msg):
    

    for i in range(0, msg.attributes['num_new_tables']):

        att = copy.deepcopy(msg.attributes)
        att['operator'] = 'populate_test_tables'
        att['table_name'] = att['table_basename'] + '_' + str(i)

        col1 = np.arange(i, api.config.num_rows+i)
        df = pd.DataFrame(col1, columns=['NUMBER']).reset_index()
        df.rename(columns={'index': 'INDEX'}, inplace=True)
        df['DIREPL_UPDATED'] = datetime.now(timezone.utc).isoformat()
        df['DIREPL_TYPE'] = 'I'
        df['NUM_MOD'] = df['NUMBER']%100
        df['DATETIME'] = datetime.now(timezone.utc) - pd.to_timedelta(df['NUM_MOD'],unit='d')
        df['DATETIME'] = df['DATETIME'].apply(datetime.isoformat)

        # ensure the sequence of the table corresponds to attribute table:columns
        att['table'] = {
            "columns": [{"class": "integer", "name": "INDEX", "nullable": False, "type": {"hana": "BIGINT"}}, \
                        {"class": "integer", "name": "NUMBER", "nullable": True, "type": {"hana": "BIGINT"}},
                        {"class": "timestamp", "name": "DATETIME", "nullable": False, "type": {"hana": "TIMESTAMP"}}, \
                        #{"class": "integer", "name": "DIREPL_PID", "nullable": True, "type": {"hana": "BIGINT"}}, \
                        {"class": "timestamp", "name": "DIREPL_UPDATED", "nullable": True, "type": {"hana": "TIMESTAMP"}}, \
                        #{"class": "string", "name": "DIREPL_STATUS", "nullable": True, "size": 1, "type": {"hana": "NVARCHAR"}}, \
                        {"class": "string", "name": "DIREPL_TYPE", "nullable": True, "size": 1,"type": {"hana": "NVARCHAR"}}], \
                        "version": 1, "name": att['table_name']}
        att['message.batchIndex'] = i
        att['message.lastBatch'] = True if  i == msg.attributes['num_new_tables'] - 1 else False
        api.logger.info('Attributes: {}'.format(att))

        #df = df[['INDEX', 'NUMBER', 'DATETIME','DIREPL_PID', 'DIREPL_UPDATED', 'DIREPL_STATUS','DIREPL_TYPE']]
        df = df[['INDEX', 'NUMBER', 'DATETIME', 'DIREPL_UPDATED',  'DIREPL_TYPE']]
        table_data = df.values.tolist()
        api.logger.info('Table inserts sent to: {}'.format(att['table_name']))
        

        api.send(outports[1]['name'], api.Message(attributes=att, body=table_data))
        api.send(outports[0]['name'], log_stream.getvalue())
        log_stream.seek(0)
        log_stream.truncate()


inports = [{'name': 'data', 'type': 'message.table', "description": "Input data"}]
outports = [{'name': 'log', 'type': 'string', "description": "Logging data"}, \
            {'name': 'table', 'type': 'message.table', "description": "msg with table"}]

api.set_port_callback(inports[0]['name'], on_data)
